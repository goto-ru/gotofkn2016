{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "tweets = pandas.DataFrame.from_csv(\"Tweets data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(tweets[::5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing\n",
    "Извлечём из твитов признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = tweets[\"SentimentText\"]\n",
    "Y = tweets[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    features = []\n",
    "    \n",
    "    \n",
    "    text = <приведите текст к нижнему регистру>\n",
    "    \n",
    "    #<для начала будем использовать частоты букв как признаки>\n",
    "    letters = \"abcdefghijklmnopqrstuvwxyz\"    \n",
    "    for l in letters:\n",
    "        features.append(text.count(l))\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "X = []\n",
    "for text in texts:\n",
    "    X.append(extract_features(text))\n",
    "X = numpy.array(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a model\n",
    "Научим на наших признаках простую линейную модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#порежем данные\n",
    "X_train = X[:70000]\n",
    "Y_train = Y[:70000]\n",
    "X_test = X[70000:]\n",
    "Y_test = Y[70000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = <обучите логистическую регрессию>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred_train = <предскажите вероятности для обучающей выборки>\n",
    "Y_pred_test = <предскажите вероятности для обучающей выборки>\n",
    "print(\"Обучение:\",roc_auc_score(Y_train,Y_pred_train))\n",
    "print(\"Тест:\",roc_auc_score(Y_test,Y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# opinion mining\n",
    "\n",
    "Давайте использовуем нашу модель чтобы понять, что людям сейчас нравится/не нравится"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "with open(\"testdata.txt\") as fin:\n",
    "    test_tweets = fin.read()[:-1].split('\\n')\n",
    "test_tweets = numpy.array(test_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print test_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_ops = []\n",
    "for tweet in test_tweets:\n",
    "    X_ops.append(extract_features(tweet))\n",
    "X_ops = numpy.array(X_ops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiments = <предскажите эмоциональную окраску x_ops>\n",
    "sentiment_order = numpy.argsort(-sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### теперь посмотрим на наиболее любимые/ненавистные людям вещи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_ids = sentiment_order[:10]\n",
    "\n",
    "for tweet, score in zip(test_tweets[best_ids], sentiments[best_ids]):\n",
    "    print score,':',tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "worst_ids = sentiment_order[-10:]\n",
    "\n",
    "for tweet, score in zip(test_tweets[worst_ids], sentiments[worst_ids]):\n",
    "    print score,':',tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_words = <список всех слов во всех твитах>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = list(set(words))\n",
    "word_to_id = {word:i for i,word in enumerate(list(words))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#выделите 1000 cлов, которые имеют наиболее разную вероятность войти в позитивный и негативный твит\n",
    "bag_of_words = <слова-признаки>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    features = []\n",
    "    \n",
    "    words = filter(len,text.lower().split())\n",
    "    \n",
    "    <bag of words для слов>\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "X = []\n",
    "for text in texts:\n",
    "    X.append(extract_features(text))\n",
    "X = numpy.array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = <обучите модель>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred_train = <предскажите вероятности для обучающей выборки copy-paste>\n",
    "Y_pred_test = <предскажите вероятности для обучающей выборки copy-paste>\n",
    "print(\"Обучение:\",roc_auc_score(Y_train,Y_pred_train))\n",
    "print(\"Тест:\",roc_auc_score(Y_test,Y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collocations\n",
    "Найдём наиболее частые коллокации и используем их как признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfinder = collocations.BigramCollocationFinder.from_words(text_words)\n",
    "cfinder.apply_freq_filter(5)\n",
    "measure = collocations.BigramAssocMeasures.raw_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(cfinder.nbest(measure,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    features = []\n",
    "    \n",
    "    <bag of words для коллокаций>\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "X = []\n",
    "for text in texts:\n",
    "    X.append(extract_features(text))\n",
    "X = numpy.array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = <обучите модель>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred_train = <предскажите вероятности для обучающей выборки copy-paste>\n",
    "Y_pred_test = <предскажите вероятности для обучающей выборки copy-paste>\n",
    "print(\"Обучение:\",roc_auc_score(Y_train,Y_pred_train))\n",
    "print(\"Тест:\",roc_auc_score(Y_test,Y_pred_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
